[repositorio_desafio-dados](https://github.com/sfer26/entrevista-dados)

# README:
# üöÄ Desafio T√©cnico ‚Äì Analista de Dados & Desenvolvedor LLM

Este reposit√≥rio cont√©m o desafio t√©cnico proposto para avalia√ß√£o das habilidades em **Engenharia de Dados, Machine Learning e Desenvolvimento com LLMs**.
O desafio est√° dividido em **duas etapas principais**, envolvendo an√°lise de dados, visualiza√ß√£o e aplica√ß√£o de modelos de aprendizado de m√°quina.

---

## üìÇ Estrutura do Projeto

* **/data** ‚Üí Cont√©m amostras de dados das cole√ß√µes do GCP (`ShoppingCart` e `ShoppingCart_v2`).
* **/notebooks** ‚Üí Jupyter Notebooks com an√°lises explorat√≥rias, pr√©-processamento e modelos preditivos.
* **/src** ‚Üí C√≥digo fonte da aplica√ß√£o, incluindo scripts de tratamento de dados, visualiza√ß√£o e integra√ß√£o.
* **/docs** ‚Üí Documenta√ß√£o de apoio e diagramas do fluxo de trabalho.

---

## üéØ Descri√ß√£o do Desafio

### 1Ô∏è‚É£ Parte 1 ‚Äì Visualiza√ß√£o de Carrinhos Abandonados

Os dados est√£o dispon√≠veis no projeto **entrevista** no **Google Cloud Platform (GCP)**, contendo as cole√ß√µes:

* **ShoppingCart**
* **ShoppingCart\_v2**

Esses dados representam eventos de **carrinhos abandonados** em um sistema de vendas de assinaturas de cursos.

#### Objetivo:

* Construir **visualiza√ß√µes interativas** (Dash, Streamlit ou outra ferramenta similar).
* Permitir **cruzamentos de informa√ß√µes relevantes** para:
  * Suporte √† **tomada de decis√£o** da √°rea de Vendas.
  * Definir **estrat√©gias de Marketing** para reduzir a taxa de abandono.
* A interface deve ser **intuitiva**, com fluxo de navega√ß√£o claro e insights acion√°veis.

---

### 2Ô∏è‚É£ Parte 2 ‚Äì Modelo de Recupera√ß√£o de Vendas

Usando a biblioteca **scikit-learn**, monte um modelo preditivo para **campanhas de recupera√ß√£o de clientes**.

#### Objetivo:

* Criar **amostras preditivas** para identificar clientes com maior probabilidade de convers√£o.
* Testar algoritmos de **aprendizado de m√°quina**, por exemplo:
  1. Redes Neurais (MLPClassifier).
  2. Regress√£o Log√≠stica.
  3. Random Forest.
* Medir a **taxa estimada de recupera√ß√£o de vendas** sobre clientes perdidos.
* Gerar relat√≥rio comparativo entre os modelos testados.

	---

## üõ†Ô∏è Tecnologias Recomendadas

* **Python 3.10+**
* **Bibliotecas**:

  * `pandas`, `numpy` ‚Üí tratamento de dados
  * `matplotlib`, `seaborn`, `plotly` ‚Üí visualiza√ß√µes
  * `scikit-learn` ‚Üí machine learning
  * `dash` ou `streamlit` ‚Üí interface interativa
* **GCP Firestore** ‚Üí origem dos dados

---

## üìä Entreg√°veis

1. **Dashboard interativo** para an√°lise de carrinhos abandonados.
2. **Modelo preditivo** documentado em Jupyter Notebook.
3. Relat√≥rio de m√©tricas (precis√£o, recall, F1-score, AUC).
4. README bem documentado explicando decis√µes, hip√≥teses e limita√ß√µes.

---

## üìå Crit√©rios de Avalia√ß√£o

* Clareza e organiza√ß√£o do c√≥digo.
* Capacidade de **extrair insights √∫teis** dos dados.
* Correta utiliza√ß√£o de **modelos preditivos**.
* Documenta√ß√£o clara e objetiva.
* Criatividade em propor solu√ß√µes que **reduzam abandono** e **aumentem convers√µes**.

---

## ‚ñ∂Ô∏è Como Executar

1. Clone este reposit√≥rio:

   ```bash
   git clone https://github.com/seu-usuario/desafio-entrevista.git
   cd desafio-entrevista
   ```

2. Crie e ative um ambiente virtual:

   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows
   ```

3. Instale as depend√™ncias:

   ```bash
   pip install -r requirements.txt
   ```

4. Execute a aplica√ß√£o:

   ```bash
   streamlit run src/app.py
   ```

   ou

   ```bash
   python src/dashboard.py
   ```

---

## üì¨ Contato

Em caso de d√∫vidas sobre este desafio, entre em contato pelo e-mail: **[desenvolvimento@soulcode.com](mailto:desenvolvimento@soulcode.com)**

----

## Links uteis
[sklearn medium artigo](https://medium.com/@habbema/introdu%C3%A7%C3%A3o-ao-scikit-learn-f00b7201dbf7)
[sklearn artigo asimov](https://hub.asimov.academy/blog/scikit-learn-o-que-e-por-que-usar-e-como-instalar/)
[regressao logistica - asimov](https://hub.asimov.academy/blog/entendendo-a-regressao-logistica/)
[arvores de decisao_python - asimov](https://hub.asimov.academy/blog/arvores-de-decisao-em-python-estrutura-e-aplicacoes/)
[metricas preditivas - data science](https://mariofilho.com/precisao-recall-e-f1-score-em-machine-learning/)

---
# Planejamento de Ataque

#### **Fase 0: Prepara√ß√£o do Ambiente e Acesso aos Dados**

-> Pipeline de ETL

- [x] **Tarefa 0.1: Fork e Clone do Reposit√≥rio.**
    - **A√ß√£o:** Primeiro, fa√ßa um **Fork** do reposit√≥rio no GitHub para a sua conta. Depois, clone _o seu fork_ para o ambiente onde vai trabalhar (seja localmente ou direto no Colab com `!git clone ...`). Isso garante que voc√™ tenha sua pr√≥pria vers√£o para trabalhar.
        
- [x] **Tarefa 0.2: Configura√ß√£o do Ambiente Virtual.**
        
- [x] **Tarefa 0.3: Autentica√ß√£o e Conex√£o com o GCP no Colab.**
    - **A√ß√£o:** Esta √© a tarefa **mais cr√≠tica** desta fase -> c√≥digo para autenticar conta do Google e permitir que o Colab acesse os dados do Firestore no projeto `entrevista`.

#### **Fase 1: An√°lise Explorat√≥ria e Dashboard (Parte 1 do Desafio)**

O foco aqui √© entender os dados de carrinhos abandonados e apresentar os achados de forma visual e interativa.

- [x] **Tarefa 1.1: ETL - Extra√ß√£o e Transforma√ß√£o.**
    
    - **A√ß√£o:** Crie um script ou c√©lulas no notebook para:
        
        1. ~~**Extrair** os dados das cole√ß√µes `ShoppingCart` e `ShoppingCart_v2` do Firestore.~~
        2. ~~**Carregar** esses dados em DataFrames do Pandas.~~
        3. **Limpar e Transformar:** Unir as duas fontes se necess√°rio, tratar dados faltantes, converter tipos de dados (especialmente datas!), e talvez criar novas colunas (ex: dia da semana, hora do abandono).
            
- **[ üìù ] Tarefa 1.2: An√°lise Explorat√≥ria de Dados (EDA).**
    
    - **A√ß√£o:** Antes de construir o dashboard; O objetivo √© encontrar os **insights** que ser√£o mostrados no dashboard.
    - **Perguntas a responder:**
        - Quais produtos ou cursos s√£o mais abandonados?
        - Qual o valor m√©dio dos carrinhos abandonados?
        - Existe um hor√°rio de pico de abandonos? E um dia da semana?
        - H√° alguma rela√ß√£o entre o m√©todo de pagamento escolhido e o abandono?
        - Qual etapa do funil de compra tem mais abandonos?

  - [x] Tarefa 1.3: Constru√ß√£o do Dashboard.**        
> Dar enfase para o uso de LOOKER, porque foi a ferramenta citada na entrevista pelo recrutador -> usar um modelo de exemplo   

#### **Fase 2: Modelo Preditivo (Parte 2 do Desafio)**

- **[ üìù ] Tarefa 2.1: Engenharia de Features e Defini√ß√£o do Target.**
    - **A√ß√£o:** Prepare um novo DataFrame espec√≠fico para o modelo.      
        1. **Definir o `target` (y):** Crie a vari√°vel-alvo dados que mostrem quais dos "clientes perdidos" **realmente voltaram a comprar** ap√≥s uma campanha. A coluna ser√° algo como `converteu_recuperacao` (com 0 ou 1).
        2. **Selecionar as `features` (X):** colunas que ajudar√£o a prever o `target`. Use os insights da EDA!             
- **[ üìù ] Tarefa 2.2: Treinamento e Avalia√ß√£o do Modelo 1 (Random Forest).**
    - **A√ß√£o:** Siga o nosso plano: comece com um, e fa√ßa-o bem.
        1. Divide os dados 
        2. Instancia e treina o `RandomForestClassifier` com `.fit()`.
        3. Fazer as previs√µes no conjunto de teste com `.predict()`.
        4. **analisar** o `classification_report` e a `confusion_matrix`. O que os n√∫meros significam para o neg√≥cio?
            
- **[ üìù ] Tarefa 2.3 (Opcional): Treinamento do Modelo 2 (Regress√£o Log√≠stica).**
    
    - **A√ß√£o:** Se o passo 2.2 correu bem e h√° tempo, copio o processo e apenas troco o modelo. Compara os resultados. Qual √© melhor em Precis√£o? E em Recall?
        

#### **Fase 3: Documenta√ß√£o e Entrega**

Empacotar tudo para a entrega.

- **[ üìù ] Tarefa 3.1: Limpeza e Coment√°rios no Notebook.**
    
    - **A√ß√£o:** Notebook limpo, com c√©lulas na ordem correta, coment√°rios explicando o que fiz, e as conclus√µes de cada etapa.
        
- **[ üìù ] Tarefa 3.2: Atualiza√ß√£o do README.**
        
- **[ üìù ] Tarefa 3.3: Preparar o Relat√≥rio Comparativo.**
       

---
### **Plano de Ataque para o Prazo**

- **Quarta:** Foco total na **Fase 0**. Conseguir ler os dados do Firestore de dentro do Colab √© a sua maior prioridade e pode ter alguns detalhes t√©cnicos.
    
- **Quinta:** Mergulhar na **Fase 1**. Fazer toda a limpeza, an√°lise explorat√≥ria e construir a primeira vers√£o do dashboard. √â um dia cheio, mas focado.
    
- **Sexta-feira:** Foco na **Fase 2 e 3**. Como os dados j√° estar√£o limpos, a parte de modelagem ser√° mais direta. Deixe as √∫ltimas horas para polir a documenta√ß√£o e o README.

---
## Organiza√ß√£o do caderno colab 
### CADERNO 1: `01_ETL_e_Analise_Exploratoria.ipynb`
-> 1 PARTE: CONEX√ÉO E CARGA DOS DADOS (ETL)
(O c√≥digo aqui ser√° a base para um script em /src)

->  PARTE 2: AN√ÅLISE EXPLORAT√ìRIA (EDA)
(Esta se√ß√£o ser√° o cora√ß√£o do seu "01_Analise_Exploratoria.ipynb")

-> PARTE 3: PREPARA√á√ÉO PARA O DASHBOARD
(O c√≥digo aqui vai gerar os dados que o Looker vai usar)

### CADERNO 2:  `02_Modelo_Preditivo.ipynb`
-> PARTE 4: ENGENHARIA DE FEATURES PARA O MODELO
(Esta se√ß√£o ser√° o come√ßo do seu "02_Modelo_Preditivo.ipynb")
-> PARTE 5: TREINAMENTO E AVALIA√á√ÉO DO MODELO
(Continua√ß√£o do "02_Modelo_Preditivo.ipynb")
(c√©lulas com o treino do RandomForest, LogisticRegression e a avalia√ß√£o)

---
# Conex√£o com firestore e extra√ß√£o dos dados

> tive erro com a conex√£o do firestore (gcp) e colab
> confundi os diretorios

-> Achava que era:
```Markdown
üìÅ entrevista (cole√ß√£o)
  ‚îî‚îÄ‚îÄ üìÑ shoppingCart (documento)
      ‚îî‚îÄ‚îÄ üìÅ shoppingCart (subcole√ß√£o)
          ‚îú‚îÄ‚îÄ üìÑ 000475912411
          ‚îú‚îÄ‚îÄ üìÑ 001043589133
          ‚îî‚îÄ‚îÄ üìÑ outros...
```

-> E era:

``` Markdown
üìÅ shoppingCart (cole√ß√£o na RAIZ)
‚îú‚îÄ‚îÄ üìÑ 000475912411
‚îú‚îÄ‚îÄ üìÑ 001043589133  
‚îú‚îÄ‚îÄ üìÑ 001372999061
‚îî‚îÄ‚îÄ üìÑ outros...

üìÅ shoppingCartV2 (outra cole√ß√£o na RAIZ)
‚îú‚îÄ‚îÄ üìÑ outros documentos...
```

> Para evitar erros: 
```python
#Cole isso sempre que n√£o souber a estrutura
collections = list(db.collections()) print("Cole√ß√µes na raiz:", [col.id for col in collections])
```

-> L√≥gica do Firestore:
``` python
# COLE√á√ÉO direta na raiz:
db.collection('nome_colecao')

# SUBCOLE√á√ÉO (dentro de um documento):
db.collection('colecao_pai').document('doc_pai').collection('subcolecao')
```

>[!example] Firestore tem uma hierarquia espec√≠fica: 
>`database ‚Üí cole√ß√µes ‚Üí documentos ‚Üí subcole√ß√µes ‚Üí documentos...`
>Estava procurando em `database ‚Üí entrevista/shoppingCart/shoppingCart` quando na verdade era `database ‚Üí shoppingCart`

#### Script da extra√ß√£o dos dados do firestore
``` python
# EXTRA√á√ÉO DE DADOS DO FIRESTORE
from google.cloud import firestore
import pandas as pd

# Configura√ß√µes do projeto
project_id = 'entrevistas-470214'
database_id = 'entrevista'
db = firestore.Client(project=project_id, database=database_id)  
print("‚úÖ Conex√£o estabelecida com Firestore") 

# EXTRA√á√ÉO shoppingCart
print("\nEXTRAINDO DADOS DE 'shoppingCart'...")
dados_shopping_cart = []
cont_v1 = 0 

for doc in db.collection('shoppingCart').stream():
cont_v1 += 1
doc_data = doc.to_dict()
doc_data['purchase_id'] = doc.id
dados_shopping_cart.append(doc_data)

if cont_v1 % 100 == 0:
print(f" Processados: {cont_v1} documentos...")  
print(f"‚úÖ shoppingCart: {cont_v1} documentos extra√≠dos") 

# EXTRA√á√ÉO shoppingCartV2
print("\nEXTRAINDO DADOS DE 'shoppingCartV2'...")
dados_shopping_cart_v2 = []
cont_v2 = 0

for doc in db.collection('shoppingCartV2').stream():
cont_v2 += 1
doc_data = doc.to_dict()
doc_data['purchase_id'] = doc.id
dados_shopping_cart_v2.append(doc_data)
 
if contador_v2 % 100 == 0:
print(f" Processados: {cont_v2} documentos...") 
print(f"‚úÖ shoppingCartV2: {cont_v2} documentos extra√≠dos")
  
# VERIFICA√á√ÉO
print("\n" + "="*60)
print("RESUMO DA EXTRA√á√ÉO:")
print(f"shoppingCart: {len(dados_shopping_cart)} documentos")
print(f"shoppingCartV2: {len(dados_shopping_cart_v2)} documentos")
print(f"Total extra√≠do: {len(dados_shopping_cart) + len(dados_shopping_cart_v2)} documentos")
  
# TESTE: Verificar estrutura dos primeiros documentos
print("\nVERIFICA√á√ÉO DE ESTRUTURA:")
if dados_shopping_cart:
print(f"Colunas shoppingCart: {list(dados_shopping_cart[0].keys())}")
else:
print("shoppingCart vazio")  

if dados_shopping_cart_v2:
print(f"Colunas shoppingCartV2: {list(dados_shopping_cart_v2[0].keys())}")
else:
print("shoppingCartV2 vazio") 

print("\n‚úÖEXTRA√á√ÉO CONCLU√çDA!")
print("Vari√°veis dispon√≠veis:")
print(" - dados_shopping_cart (lista de dicts)")
print(" - dados_shopping_cart_v2 (lista de dicts)")
```


#### Script de cria√ß√£o de Dataframes para come√ßar a explorar os dados pra tratamento e limpeza

``` python
# CRIA√á√ÉO DE DATAFRAMES
import pandas as pd
print("CRIANDO DE DATAFRAMES")
print("="*60) 

# DATAFRAME 1: shoppingCart
df_shopping_cart = pd.DataFrame(dados_shopping_cart)  

# Adicionar coluna identificadora da origem do dado
if not df_shopping_cart.empty:
df_shopping_cart['collection_source'] = 'shoppingCart'  
print(f"‚úÖ df_shopping_cart criado: {df_shopping_cart.shape}")

# DATAFRAME 2: shoppingCartV2
df_shopping_cart_v2 = pd.DataFrame(dados_shopping_cart_v2) 
# Adicionar coluna identificadora
if not df_shopping_cart_v2.empty:
df_shopping_cart_v2['collection_source'] = 'shoppingCartV2' 
print(f"‚úÖ df_shopping_cart_v2 criado: {df_shopping_cart_v2.shape}")
  
# DATAFRAME Unificado
# Combinar os dois DataFrames
df_shopping_cart_unificado = pd.concat([
df_shopping_cart,
df_shopping_cart_v2
], ignore_index=True)
 

print(f"‚úÖ df_shopping_cart_unificado criado: {df_shopping_cart_unificado.shape}")

```

##### Cria√ß√£o da Coluna Identificadora (collection_source)

Antes de unificar os dois DataFrames (df_shopping_cart e df_shopping_cart_v2), uma coluna chamada collection_source foi adicionada a cada um deles. O valor desta coluna √© uma string que identifica a cole√ß√£o de origem de cada registro ('shoppingCart' ou 'shoppingCartV2').

Esta etapa √© crucial por tr√™s motivos principais:
- Rastreabilidade (Data Provenance): Ap√≥s a uni√£o dos DataFrames, a informa√ß√£o sobre de qual fonte cada linha veio seria permanentemente perdida. Esta coluna age como uma "etiqueta", garantindo que, mesmo no DataFrame final unificado, possamos rastrear a origem de cada registro.
- An√°lise Comparativa:  A coluna se torna uma ferramenta poderosa para segmentar e comparar os dois conjuntos de dados. Com ela, posso facilmente responder perguntas como: "A taxa de abandono √© diferente entre os dados da V1 e da V2?" ou "O pre√ßo m√©dio dos produtos varia entre as duas fontes?".
- Depura√ß√£o (Debugging): Se encontrarinconsist√™ncias, erros ou valores inesperados em um subconjunto dos dados unificados, esta coluna permite isolar rapidamente a fonte original do problema (V1 ou V2), facilitando a investiga√ß√£o e a corre√ß√£o.

---
# Limpeza e tratamento

### Validar hipotese que V2 seja as vendas convertidas
-> n√£o tem nada a ver, os dois df possuem abandono de carrinho
-> s√£o apenas 'vers√µes' diferentes
-> usar df_unificado j√° que as diferen√ßas n√£o v√£o interferir na EDA
	
``` Markdown
AN√ÅLISE DE COLUNAS:
- Colunas comuns: 18
- Colunas apenas em shoppingCart: 0
- Colunas apenas em shoppingCartV2: 2
- Exclusivas de shoppingCartV2: ['brand', 'ticket_id']
```

> tratar 'brand' e 'ticket_id' para o que vier nulo da V1 n√£o atrapalhe
> brand ser√° mantido, pode ter insights legais ao relacionar com price
> ticket_id: dropar -> n√£o tem relev√¢ncia. Melhor dropar j√° que tem diferen√ßa do df_shopping_cart para V2, s√≥ vai acumular servi√ßo para tratar os nulos que vierem do primeiro df

### Limpar e selecionar colunas uteis
#### Remo√ß√£o: cpf, email, phoneNumber, id, webhook, customer_id, subscription_id, shoppingCartHubspotId
- Decis√£o:
``` python
# Lista de colunas para dropar
colunas_para_remover = ['ticket_id', 'cpf', 'email', 'phoneNumber', 'id',
'webhook', 'customer_id', 'subscription_id', 'shoppingCartHubspotId']
```

``` Markdown
Colunas removidas com sucesso!
Colunas restantes no DataFrame 'df_limpo':
['lastName', 'firstName', 'price', 'paymentMethod', 'purchaseStatus', 'planName', 'createdAt', 'integrationStatus', 'purchase_id', 'collection_source', 'brand']
```

> ==MANTER 'purchase_id' como identificador √∫nico==
#### Renomear colunas
- Snake-case
- Portugu√™s
- Descritivo mas conciso
``` python
# Renomear colunas mantidas
novos_nomes = {
'lastName': 'sobrenome',
'firstName': 'nome',
'price': 'preco',
'paymentMethod': 'metodo_pagamento',
'purchaseStatus': 'status_compra',
'planName': 'plano',
'createdAt': 'data_criacao',
'integrationStatus': 'status_integracao',
'purchase_id': 'id_compra',
'collection_source': 'origem_dados',
'brand': 'marca'
}
```
### Tratar valores nulos/brancos (missing values)
- brand e ticket_id: Para os registros que vieram da V1, esses valores s√£o nulos. Posso preench√™-los com um valor que indique isso
		- brand: N/A
		- ~~ticket_id~~: 0 -> *coluna dropada*
		-- paymentMethod, planName: N√£o Informado
	- price: alguns est√£o vazios -> erro ? VERIFICAR se tem rela√ß√£o com algum status -> prencher com 0 (talvez)
		- Erro de sistema ‚Üí mediana/m√©dia 
		- Abandono precoce ‚Üí valor especial (-1) 
		- Produto gratuito ‚Üí realmente 0

```
'marca': 'Nao_Informado',
'metodo_pagamento': 'Nao_Selecionado',
'plano': 'Nao_Definido'
```

#### Investiga√ß√£o de nulos da coluna 'price'
-> relacionando com status_compra

```
Pre√ßos nulos: 8108
Distribui√ß√£o de status com pre√ßo nulo:
status_compra
Abandoned    5716
Success      2392
Name: count, dtype: int64

# nao tem a ver com o status da compra -> os nulos acontecem tanto em carrinhos abandonados quanto os convertidos em pedidos
```

-> origem:
```
Missing por origem:
origem_dados
shoppingCart      4054
shoppingCartV2    4054
Name: count, dtype: int64
```
	# tamb√©m n√£o diz muita coisa. os nulos s√£o iguais em cada origem

-> temporal ? (algum per√≠odo de tempo)

``` Markdown
data_criacao
2023-03    8108
Name: count, dtype: int64

MAR√áO! Todos os nulos s√£o do per√≠odo de 2023-03. Pode ser um erro t√©cnico\nUsar mediana do per√≠odo adjascente\nTratar data antes de fazer o tratamento de nulos de 'price'
```

DECIS√ÉO: Mediana do per√≠odo adjascente
``` python
# Mediana dos adjacentes
# converter para str e verificar se o m√™s est√° na lista
# verifica se o pre√ßo n√£o √© nulo
# combinar os filtros com '&'
# seleciona e calcula a mediana desses valores
mediana_contexto = df_limpo[
(df_limpo['data_criacao'].dt.strftime('%Y-%m').isin(['2023-02', '2023-04'])) &
(df_limpo['preco'].notna())
]['preco'].median()
```

	- depois foi s√≥ imputar em mar√ßo o valor da mediana:
	  Pre√ßos imputados com: R$ 682.80
	Missing values restantes: 0

#### Por que usar mediana na substitui√ß√£o de valores nulos do pre√ßo?
1. **Mais conservadora** - n√£o vai distorcer suas an√°lises
2. **Padr√£o na ind√∫stria** para dados financeiros/pre√ßos
3. **Robusta** - funciona bem independente da distribui√ß√£o
4. **Defens√°vel** - sempre √© uma escolha segura

> [!question] Quando considerar m√©dia???
 Se tiver certeza que: 
> 1. Distribui√ß√£o √© aproximadamente normal
>2. Poucos outliers
>3. Distribui√ß√£o √© aproximadamente normal
>4. Poucos outliers
>5. Quer preservar a "informa√ß√£o" dos valores extremos
>
-> Exemplo: se produtos premium s√£o importantes para an√°lise
 Mas mesmo assim, pode usar m√©dia truncada (remove extremos) 



---
### Eng. de Feature (novas colunas, reestrutura√ß√£o)
- Data: coluna 'createdAt'
		- organizar mes, dia_semana, hora

#### 1. Features Temporais

- **Novas Colunas:** `ano`, `mes`, `dia`, `dia_semana`, `hora`, `periodo_dia`.
- **Descri√ß√£o:** Estas colunas quebram a data e hora exata da cria√ß√£o do carrinho (`data_criacao`) em componentes mais f√°ceis de analisar e agrupar.
- **L√≥gica de Cria√ß√£o:**
    - As colunas `ano`, `mes`, `dia`, `dia_semana` e `hora` foram extra√≠das diretamente da coluna `data_criacao` usando as fun√ß√µes de data e hora do Pandas (`.dt`).
    - A coluna `periodo_dia` foi criada para agregar as 24 horas em quatro categorias mais simples: Madrugada (0h-5h), Manh√£ (6h-11h), Tarde (12h-17h) e Noite (18h-23h).
- **Objetivo Anal√≠tico:** Identificar padr√µes de comportamento baseados no tempo. Permite responder perguntas como: "A taxa de abandono √© maior em algum `dia_semana` espec√≠fico?" ou "O `periodo_dia` influencia a decis√£o de compra?"
#### 2. Feature de Pre√ßo Categ√≥rico
- **Nova Coluna:** `faixa_preco`.
- **Descri√ß√£o:** Segmenta os produtos em quatro categorias de pre√ßo, transformando uma vari√°vel num√©rica cont√≠nua em uma categ√≥rica.
- **L√≥gica de Cria√ß√£o:** A coluna `preco` foi discretizada usando a fun√ß√£o `pd.cut` do Pandas, com as seguintes faixas: `baixo` (at√© 500), `medio` (501-650), `alto` (651-750) e `premium` (acima de 750).
- **Objetivo Anal√≠tico:** Simplificar a an√°lise de pre√ßo e criar segmentos de valor. Permite investigar: "Clientes que compram produtos na faixa 'Premium' abandonam mais o carrinho?" ou "Qual a faixa de pre√ßo mais popular?".
#### 3. Features de Regra de Neg√≥cio
- **Novas Colunas:** `tipo_plano`, `converteu`.
- **Descri√ß√£o:** Cria√ß√£o de indicadores bin√°rios que refletem l√≥gicas importantes para o neg√≥cio, simplificando an√°lises complexas.
- **L√≥gica de Cria√ß√£o:**
    - `tipo_plano`: Classifica os planos em 'Simples' ou 'Combo'. A regra, inferida dos dados, define como 'Combo' qualquer plano que contenha "Assinatura M" em seu nome, indicando a jun√ß√£o de mais de um produto.
    - `converteu`: √â uma flag booleana (`True`/`False`) que indica se a venda foi bem-sucedida. Foi criada a partir da coluna `status_compra`, recebendo `True` quando o status √© 'Success'.
- **Objetivo Anal√≠tico:** Criar vari√°veis-chave para o dashboard. A coluna `converteu` √© a nossa **vari√°vel alvo** principal, permitindo calcular taxas de convers√£o de forma direta para qualquer segmento. A coluna `tipo_plano` permite comparar a performance de diferentes ofertas de produto.
    

---
### EDA
[correlacao em python](https://medium.com/@joaopedro.thereziano/an%C3%A1lise-de-correla%C3%A7%C3%A3o-utilizando-python-30bcf29423c3)


![[Pasted image 20250828212026.png]]

### Primeiros insights: HORAS E DIAS
#### 1. O Fen√¥meno das 14h: A "Hora de Ouro"

- **Observa√ß√£o:** √Äs 14h, voc√™ tem o **maior volume de vendas E a maior taxa de convers√£o**. O ticket m√©dio nesse hor√°rio √© bom, mas n√£o √© o mais alto do dia.
- **Interpreta√ß√£o:** Este √©, sem d√∫vida, o seu hor√°rio mais importante. √â quando o maior n√∫mero de clientes est√° ativo e, ao mesmo tempo, mais propenso a comprar. A combina√ß√£o de alto tr√°fego com alta inten√ß√£o de compra faz deste o motor do seu faturamento di√°rio.
- **Hip√≥tese (Persona):** Pode ser o pico do "hor√°rio de almo√ßo" ou "p√≥s-almo√ßo", onde as pessoas usam uma pausa no trabalho para finalizar compras. Por ser um hor√°rio de massa, os produtos comprados podem ser os mais populares e de valor mediano, o que explica por que o ticket m√©dio n√£o √© o mais alto.
- **A√ß√£o Estrat√©gica:** **M√°xima agressividade aqui.** Campanhas de marketing, e-mails e notifica√ß√µes push devem ser concentradas para chegar aos clientes um pouco antes e durante este hor√°rio. Garanta que o site esteja com performance m√°xima e o estoque dos produtos principais esteja abastecido.
#### 2. Os Compradores Noturnos (22h - 23h): Efici√™ncia e Volume
- **Observa√ß√£o:** Este per√≠odo tem a **segunda maior onda de vendas** e uma **taxa de convers√£o alt√≠ssima**, rivalizando com o pico das 14h.
- **Interpreta√ß√£o:** Este √© outro bloco de hor√°rio extremamente valioso. S√£o clientes que provavelmente est√£o comprando de casa, com calma, ap√≥s o dia de trabalho e outras obriga√ß√µes.
- **Hip√≥tese (Persona):** O comprador "relaxando no sof√°". Eles est√£o navegando com calma, talvez no celular ou tablet. S√£o decididos e sabem o que querem, o que explica a alta convers√£o.
- **A√ß√£o Estrat√©gica:** Campanhas de remarketing s√£o excelentes para este hor√°rio. Lembre o cliente daquele produto que ele viu mais cedo. Ofertas "s√≥ hoje √† noite" podem criar um senso de urg√™ncia e impulsionar ainda mais as vendas.
#### 3. A Anomalia da Madrugada (aprox. 4h - 6h): Poucos, mas Valiosos
- **Observa√ß√£o:** O volume de vendas e a taxa de convers√£o s√£o **extremamente baixos**. No entanto, o **maior pico de Ticket M√©dio do dia acontece √†s 6h da manh√£**.
- **Interpreta√ß√£o:** Esta √© a an√°lise mais interessante! Os pouqu√≠ssimos clientes que compram neste hor√°rio n√£o est√£o navegando por acaso. Eles est√£o fazendo compras de **alto valor**, de forma planejada e decidida.
- **Hip√≥tese (Persona):** Podem ser dois perfis:
    1. **Comprador B2B (Empresas):** Algu√©m come√ßando o dia de trabalho e comprando um item de alto valor necess√°rio para a empresa.
    2. **Comprador Decidido:** Algu√©m que j√° pesquisou, tomou a decis√£o e est√° apenas executando a compra de um item caro (um eletr√¥nico, um pacote de viagem) em um momento de tranquilidade, sem distra√ß√µes.
- **A√ß√£o Estrat√©gica:** N√£o invista em marketing de massa aqui. Em vez disso, investigue **QUAIS** produtos s√£o vendidos nesses hor√°rios. Isso pode te dar insights sobre seus itens de luxo ou de maior valor. Garanta que a experi√™ncia de compra para esses itens seja impec√°vel.
#### 4. O Per√≠odo da Manh√£ (9h - 12h): A Calmaria e a Prepara√ß√£o
- **Observa√ß√£o:** O volume de vendas e a taxa de convers√£o s√£o modestos, e o ticket m√©dio tem uma queda, principalmente √†s 9h e 12h.
- **Interpreta√ß√£o:** Este parece ser um per√≠odo de "descoberta" e "pesquisa". As pessoas est√£o navegando, adicionando itens ao carrinho, comparando pre√ßos, mas n√£o est√£o prontas para finalizar a compra.
- **Hip√≥tese (Persona):** O "planejador". A pessoa est√° no trabalho, v√™ algo que gosta, mas deixa para decidir e comprar na hora do almo√ßo (o que explica o pico das 14h).
- **A√ß√£o Estrat√©gica:** O foco aqui n√£o √© a convers√£o imediata. Use este per√≠odo para campanhas de engajamento: mostre novidades, guias de como usar um produto, reviews. O objetivo √© "aquecer" o cliente para que ele converta mais tarde, nos hor√°rios de pico.
### Sum√°rio Estrat√©gico
- **Otimize para os Picos (14h, 22-23h):** Concentre 80% do seu esfor√ßo de marketing e opera√ß√µes para garantir que tudo funcione perfeitamente nestes hor√°rios.
- **Investigue a Anomalia (4-6h):** Descubra o que est√° sendo vendido de madrugada. Isso pode revelar um nicho de mercado de alto valor que voc√™ n√£o conhecia.
- **Nutra os Clientes da Manh√£ (9-12h):** Use conte√∫do e engajamento para preparar os clientes para a compra que eles far√£o mais tarde.
- **Agende Manuten√ß√µes (5-9h):** Use o per√≠odo de menor atividade para qualquer atualiza√ß√£o t√©cnica, minimizando o impacto.
---
### Insights VENDAS E CARRINHOS ABANDONADOS
#### Insight 1: O Tamanho do Problema (O Ponto de Partida)

- **Gr√°fico Principal:** O Gr√°fico de Pizza ("Distribui√ß√£o Percentual do Status das Compras").
    
- **Insight para a Diretoria/Gest√£o:** A primeira e mais impactante informa√ß√£o √© a propor√ß√£o. Para cada **25.7%** de compras aprovadas, temos **62.9%** de carrinhos abandonados. Estamos convertendo apenas uma fra√ß√£o do nosso potencial. O problema do abandono √© o principal "ladr√£o de receita" da empresa e precisa de aten√ß√£o imediata.
    
- **No Dashboard:** Este gr√°fico deve ser o destaque na p√°gina inicial. Ele justifica a import√¢ncia de todo o resto da an√°lise.
    
#### Insight 2: ONDE estamos perdendo mais dinheiro?

- **Gr√°ficos:** O "Top Planos por Faturamento" (a vers√£o limpa, sem o "nao_definido").
    
- **Insight para a √°rea de VENDAS:** A perda de receita n√£o √© distribu√≠da igualmente. Ela est√° massivamente concentrada na **"Assinatura Tech Social ou Aluno"** (R$556 mil em carrinhos abandonados). A equipe de Vendas pode usar isso para focar em entender as obje√ß√µes espec√≠ficas deste plano. O processo de venda dele √© claro? As vantagens s√£o bem comunicadas? O potencial de ganho r√°pido est√° em otimizar a venda deste plano.
    

#### Insight 3: POR QU√ä os clientes desistem? (As Hip√≥teses)

Aqui usamos os gr√°ficos que cruzam informa√ß√µes para cria
- **Gr√°fico 1:** "Taxa de Abandono por Tipo de Plano" (Simples vs. Combo).
    
    - **Insight para MARKETING:** Planos **'Simples' s√£o abandonados com mais frequ√™ncia** que 'Combos'. Isso sugere que, ao comprar um item avulso, o cliente sente mais incerteza ("_Ser√° que √© s√≥ isso que eu preciso?_") ou percebe menos valor.
        
    - **Estrat√©gia Acion√°vel:** Na p√°gina do carrinho de um plano 'Simples', **oferecer o 'Combo' como um upgrade de melhor custo-benef√≠cio**. Isso pode reduzir a hesita√ß√£o e aumentar o ticket m√©dio.
        
- **Gr√°fico 2:** "Taxa de Convers√£o por Faixa de Pre√ßo".
    
    - **Insight para MARKETING e VENDAS:** A convers√£o **cai drasticamente na faixa de pre√ßo 'm√©dia'**. Isso √© o "Vale da Incerteza": o produto n√£o √© barato para ser um impulso, nem caro para ter um valor percebido alt√≠ssimo. √â onde o cliente mais pensa.
        
    - **Estrat√©gia Acion√°vel:** Para os produtos de faixa de pre√ßo 'm√©dia', a p√°gina de checkout e o carrinho precisam ser refor√ßados com **provas sociais (reviews), selos de garantia, clareza sobre o valor entregue e talvez um chat de suporte proativo**. O objetivo √© reduzir o atrito e a inseguran√ßa nesse segmento cr√≠tico.
        

#### Insight 4: QUANDO os clientes desistem?

- **Gr√°ficos:** Dashboard original de an√°lise hor√°ria (Volume de Vendas/Abandonos por Hora).
    
- **Insight para MARKETING:** O abandono acontece em padr√µes. Se o pico de abandonos em volume tamb√©m √© √†s 14h, isso abre uma oportunidade clara.
    
- **Estrat√©gia Acion√°vel:** Criar campanhas de **retargeting (e-mail ou an√∫ncios) de alta urg√™ncia** para carrinhos abandonados nos hor√°rios de pico. Exemplo: "Esqueceu algo no carrinho? Volte em at√© 1 hora e finalize sua compra com 10% de desconto."

### **P√°gina 2: Diagn√≥stico do Abandono (Onde & Por Qu√™?)**

**Narrativa:** "Ok, o problema √© grande. Mas _onde_ exatamente estamos perdendo clientes e _por que_ eles desistem?" Esta √© a p√°gina para os gerentes de Marketing e Vendas.

**Layout / Design:**


---

### **P√°gina 3: An√°lise Detalhada (Deep Dive)**

**Narrativa:** "Me d√™ a lista de todos os carrinhos com uma caracter√≠stica espec√≠fica." Esta √© a p√°gina para a equipe de opera√ß√£o, para a√ß√µes diretas.

**Layout / Design:**

- **Topo (Filtros Avan√ßados):** Coloque filtros poderosos e vis√≠veis para todas as principais dimens√µes: `status_compra`, `faixa_preco`, `tipo_plano`, `metodo_pagamento`, `dia_semana`, `hora`.
- **Corpo da P√°gina (A Lista):** O elemento principal aqui √© uma **Tabela**.
    - **Dados:** A tabela mostra os dados detalhados (`id_compra`, `plano`, `preco`, `data_criacao`, etc.).
    - **Interatividade:** A tabela √© 100% filtrada pelos controles no topo da p√°gina. O usu√°rio pode, por exemplo, filtrar por "Status: Abandoned", "Faixa de Pre√ßo: m√©dia" e "Dia: Segunda-feira" para ver a lista exata de carrinhos que se encaixam nesse perfil e talvez export√°-la para uma a√ß√£o de marketing.
        
### Dicas Finais de Design e Narrativa:

- **Cores:** Use uma paleta consistente. Verde para sucesso/convers√£o, vermelho/laranja para abandono/falha, e uma cor neutra (azul ou cinza) para volume/contagem.
#### Op√ß√£o 1: Paleta "Confian√ßa e Intelig√™ncia" (O Padr√£o Tech)

Esta √© a abordagem mais cl√°ssica e segura. Pense em marcas como IBM, Facebook, LinkedIn. Ela transmite seriedade e confian√ßa.
- **Psicologia:** Azul inspira confian√ßa, calma e intelig√™ncia. Cinza escuro denota profissionalismo e sofistica√ß√£o.
- **Cores Principais:**
    - **Fundo:** Um cinza bem escuro (quase preto, # 1E1E1E) ou um branco/cinza muito claro.
    - **Cores Categ√≥ricas:** Uma escala de **azuis** e **turquesas**.
    - **Destaques:** Verde brilhante para n√∫meros positivos e Laranja/Vermelho para n√∫meros negativos.
- **Exemplo de Uso:** Um dashboard em "dark mode" com gr√°ficos em tons de azul, o KPI de convers√£o em verde e a taxa de abandono em laranja.

----
### ==**O Roteiro do Dashboard: "A Jornada do Cliente que Perdemos"**

O objetivo √© contar uma hist√≥ria em 3 atos (3 p√°ginas/abas), guiando o usu√°rio do problema geral at√© a solu√ß√£o acion√°vel.

#### **P√°gina 1: O Problema em N√∫meros (O Diagn√≥stico de 30 Segundos)**

**Narrativa:** "Qual √© o tamanho real do nosso problema? Em 30 segundos, qualquer diretor precisa entender a oportunidade que estamos perdendo."

**Layout e Design:**

- **T√≠tulo Principal (no topo):** Use o seu t√≠tulo, √© perfeito: "**O Maior Concorrente da Empresa Somos N√≥s Mesmos**"
    
- **Linha de KPIs Principais (Scorecards):**
    
    - **KPI 1 (Destaque):** `Taxa de Abandono: 62.9%` (use a cor de alerta, laranja ou vermelho).
        
    - **KPI 2:** `Receita Perdida: R$ 914.286` (tamb√©m em cor de alerta).
        
    - **KPI 3:** `Receita Realizada: R$ 556.728` (em cor positiva, verde).
        
    - **KPI 4:** `Total de Carrinhos: 14.475` (em cor neutra, azul ou cinza).
        
- **Gr√°fico Central:** Um **Gr√°fico de Anel (Donut Chart)** mostrando a "Distribui√ß√£o de Status de Compra". Destaque a fatia de `Abandoned` com uma cor forte.
    
- **Gr√°fico de Contexto (Linha do Tempo):** Um **Gr√°fico de Linha** simples mostrando o total de `Carrinhos Criados` vs. `Carrinhos Abandonados` ao longo dos meses. Isso mostra se o problema est√° piorando.
    
- **Caixa de Texto (O Chamado):** No canto, seu texto de contexto: _"Este dashboard revela os padr√µes por tr√°s do abandono de carrinho... transformando dados em estrat√©gias acion√°veis."_
    
#### **P√°gina 2: O Diagn√≥stico (Onde, Quando e Por Qu√™?)**

**Narrativa:** "Ok, o problema √© grande. Agora, vamos encontrar os pontos de maior 'vazamento' e entender os motivos."

**Layout e Design (a grade 2x2):**

- **Quadrante 1 (QUANDO):** O **Gr√°fico de Linha da Taxa de Convers√£o por Hora**.
    - **T√≠tulo:** "A 'Hora de Ouro': O pico de convers√£o acontece √†s 14h"

- **Quadrante 2 (ONDE):** O **Gr√°fico de Barras Horizontais do Faturamento Perdido por Plano**. 
    - **T√≠tulo:** "Onde o Dinheiro Vaza? 'Assinatura Tech Social' lidera as perdas

- **Quadrante 3 (POR QU√ä - Pre√ßo e Produto):** **Dois gr√°ficos de barras menores, lado a lado**.   
    - Taxa de Convers√£o por `Faixa de Pre√ßo`.
    - Taxa de Abandono por `Tipo de Plano` (Simples vs. Combo).

- **Quadrante 4 (POR QU√ä - Pagamento):** O **Gr√°fico de Barras Empilhadas 100%** de Status por `M√©todo de Pagamento`.
    - **T√≠tulo:** "Onde a Experi√™ncia Quebra? O Atrito no Pagamento"
    - **Caixa de Texto de Insight ao lado deste gr√°fico:**
        > **"M√©todo de Pagamento Obsoleto:** O gr√°fico revela que o **Boleto** possui a maior propor√ß√£o de carrinhos abandonados. A hip√≥tese √© que a complexidade e o tempo de espera do m√©todo fazem o cliente "esfriar" e desistir da compra, sendo um dos principais vil√µes da nossa convers√£o."

#### **P√°gina 3: O Plano de A√ß√£o (Como Resolver?)**

**Narrativa:** "Analisar n√£o √© o suficiente. Com base nos dados, aqui est√£o as a√ß√µes recomendadas para recuperar a receita perdida." Esta p√°gina √© para a a√ß√£o.

**Layout e Design (um plano estrat√©gico, n√£o apenas gr√°ficos):**

- **T√≠tulo Principal:** "Da An√°lise √† A√ß√£o: Um Plano para Reduzir o Abandono em 20%"
    
- **Coluna 1: Quick Wins (Resultados R√°pidos)**
    
    - Use **Caixas de Texto com √çcones** para cada a√ß√£o.
        
    - ‚úÖ **A√ß√£o 1 (Produto):** "Promover Upgrade de 'Simples' para 'Combo' no carrinho." **Insight:** Combos abandonam 11% a menos.
        
    - ‚úÖ **A√ß√£o 2 (Pre√ßo):** "Refor√ßar provas sociais (reviews, garantias) na faixa de pre√ßo 'M√©dia'." **Insight:** √â a faixa com a menor taxa de convers√£o (19%).
        
    - ‚úÖ **A√ß√£o 3 (Marketing):** "Criar campanha de retargeting de urg√™ncia focada no pico das 14h." **Insight:** √â o hor√°rio de maior volume e efici√™ncia.
	- ‚úÖ **A√ß√£o 4 (Pagamento):** "**Realizar teste A/B removendo a op√ß√£o 'Boleto'** para o plano 'Tech Social' e promovendo o PIX."

- _Insight: Boleto √© o m√©todo com a maior taxa de abandono._

### Op√ß√£o 1: Paleta "Confian√ßa e Intelig√™ncia" (O Padr√£o Tech)

Esta √© a abordagem mais cl√°ssica e segura. Pense em marcas como IBM, Facebook, LinkedIn. Ela transmite seriedade e confian√ßa.

- **Psicologia:** Azul inspira confian√ßa, calma e intelig√™ncia. Cinza escuro denota profissionalismo e sofistica√ß√£o.
    
- **Cores Principais:**
    - **Fundo:** Um cinza bem escuro (quase preto, # 1E1E1E) ou um branco/cinza muito claro.
    - **Cores Categ√≥ricas:** Uma escala de **azuis** e **turquesas**.
    - **Destaques:** Verde brilhante para n√∫meros positivos e Laranja/Vermelho para n√∫meros negativos.
- **Exemplo de Uso:** Um dashboard em "dark mode" com gr√°ficos em tons de azul, o KPI de convers√£o em verde e a taxa de abandono em laranja.
### Op√ß√£o 2: Paleta "Inova√ß√£o e Criatividade" (A Moderna)

Esta paleta √© mais vibrante e passa uma imagem de uma empresa moderna, criativa e energ√©tica. Pense em marcas que querem se destacar.

- **Psicologia:** Roxo est√° associado √† criatividade e sabedoria. Teal (verde-azulado) representa inova√ß√£o. Laranja traz energia.
- **Cores Principais:**
    - **Fundo:** Cinza m√©dio ou branco.
    - **Cores Categ√≥ricas:** Uma combina√ß√£o de **Roxo**, **Teal** e **Laranja**.
    - **Destaques:** Verde para sucesso, Vermelho para falha.
- **Exemplo de Uso:** Gr√°ficos de barra com cada categoria (ex: tipo de plano) em uma dessas cores. Fica visualmente bem din√¢mico.
### Op√ß√£o 3: Paleta "Crescimento e Conhecimento" (A Inspiradora)

Esta paleta usa cores que remetem a crescimento, natureza e ilumina√ß√£o. √â √≥tima para uma marca com um prop√≥sito educacional forte.

- **Psicologia:** Verde representa crescimento e sucesso. Amarelo/Dourado remete a conhecimento, valor e otimismo.
- **Cores Principais:**
    - **Fundo:** Branco ou um tom "creme" bem suave.
    - **Cores Categ√≥ricas:** Uma escala de **verdes** e **cinzas**.
    - **Destaques:** Um **amarelo/dourado** para destacar os KPIs mais importantes e um vermelho para alertas.
- **Exemplo de Uso:** Um dashboard com visual "clean", onde os gr√°ficos de crescimento s√£o em verde e os n√∫meros principais brilham em dourado.

---

### Regras de Ouro (Mais Importante que a Paleta)

Independentemente da paleta que voc√™ escolher, siga estas regras para o dashboard ficar claro e acion√°vel:

1. **Use Cores Sem√¢nticas:** Reserve cores espec√≠ficas para significados espec√≠ficos. Isso √© crucial.
    
    - üü¢ **Verde:** Sempre para coisas boas (Convers√£o, Sucesso, Aumento de Vendas).
        
    - üî¥ **Vermelho / Laranja:** Sempre para coisas ruins (Abandono, Falha, Queda nas Vendas).
        
    - üîµ **Azul / Cinza:** Para dados informativos e neutros (Volume, Contagem Total).
        
2. **Menos √© Mais:** N√£o use 10 cores diferentes. Escolha de 3 a 5 cores principais e use varia√ß√µes de tons. Um dashboard limpo √© mais profissional.
    
3. **Pense em Acessibilidade:** Evite colocar vermelho e verde lado a lado para representar "bom" vs. "ruim", pois pessoas com daltonismo podem n√£o diferenci√°-los. Use tamb√©m √≠cones (seta para cima ‚ñ≤, seta para baixo ‚ñº) ou t√≠tulos claros para refor√ßar a mensagem.
    

**Dica B√¥nus:** Use uma ferramenta como o **Coolors.co** para te ajudar a gerar paletas harmoniosas. Voc√™ pode "travar" uma cor (ex: um verde que voc√™ gostou) e ele gera outras que combinam.
- **T√≠tulos:** Cada t√≠tulo de gr√°fico deve ser uma **afirma√ß√£o** ou uma **pergunta**, como sugeri acima. Isso √© muito mais poderoso do que t√≠tulos gen√©ricos como "Status vs. Pagamento".

---
# modelos preditivos

[[Modelos preditivos]]

### Tabela Comparativa R√°pida

|Caracter√≠stica|Regress√£o Log√≠stica|Random Forest|Rede Neural (MLP)|
|---|---|---|---|
|**Analogia**|O Estat√≠stico Cauteloso|O Comit√™ de Especialistas|O C√©rebro Artificial|
|**Complexidade**|Baixa|M√©dia|Alta|
|**Velocidade**|Muito R√°pida|M√©dia / Lenta|Lenta / Muito Lenta|
|**Interpretabilidade**|**Excelente**|Boa (Import√¢ncia das Features)|**Muito Baixa**|
|**Poder de Predi√ß√£o**|Bom para padr√µes simples|**Excelente** para padr√µes gerais|**Potencialmente o maior**, para padr√µes complexos|
|**Necessidade de Preparar Dados**|Baixa|Baixa|**Alta (Obrigat√≥rio)**|

> a estrat√©gia de come√ßar com o **Random Forest** (para buscar alta performance) ou com a **Regress√£o Log√≠stica** (para ter um resultado r√°pido e interpret√°vel) continua sendo a mais segura e eficiente para o prazo.

---
# Come√ßando trabalho preditivo

## Alerta Importante: Vazamento de Dados (Data Leakage)

Antes de escrever o c√≥digo, um ponto crucial: para prever se um cliente converteu, n√£o podemos usar colunas que j√° contenham essa resposta.
    Colunas a serem EXCLU√çDAS das features:
        sobrenome, nome, id_compra, data_criacao: S√£o identificadores, n√£o caracter√≠sticas do comportamento.
        status_compra, abandonou: S√£o praticamente a mesma informa√ß√£o que converteu. Us√°-las seria "trapacear", e o modelo n√£o aprenderia nada √∫til para prever novos clientes.
        taxa_conversao_hora, taxa_conversao_dia: Estas colunas foram calculadas usando agrega√ß√µes de dados que incluem o resultado da convers√£o. Us√°-las tamb√©m causaria vazamento de dados.

---
1. **Etapa 1: Prepara√ß√£o dos Dados (Limpeza e Sele√ß√£o)**: Vamos carregar o conjunto de dados e separar as colunas que voc√™ identificou como _features_ da coluna alvo, a vari√°vel `converteu`. Isso garantir√° que o modelo use apenas as informa√ß√µes apropriadas para a predi√ß√£o.
2. **Etapa 2: Pr√©-processamento e Engenharia de Atributos**: Nesta etapa, lidaremos com as vari√°veis categ√≥ricas (como 'metodo_pagamento', 'faixa_preco', e 'tipo_plano'), transformando-as em um formato num√©rico que o modelo possa entender, provavelmente usando a t√©cnica de _One-Hot Encoding_.
3. **Etapa 3: Modelagem Preditiva**: Selecionaremos um algoritmo de aprendizado de m√°quina e treinaremos o modelo com base nas _features_ pr√©-processadas e na vari√°vel alvo.
4. **Etapa 4: Avalia√ß√£o do Modelo**: Analisaremos o desempenho do modelo usando m√©tricas relevantes para problemas de classifica√ß√£o, como precis√£o, recall e a matriz de confus√£o.
    
df depois do _One-Hot Encoding_.
![[Pasted image 20250829181126.png]]
>**One-Hot Encoding** √© uma t√©cnica que transforma dados categ√≥ricos (texto) em um formato num√©rico que os algoritmos de aprendizado de m√°quina podem processar.
> As features `metodo_pagamento`, `faixa_preco` e `tipo_plano` cont√™m textos como 'cartao', 'nao_selecionado', 'alto', 'simples', etc. Para um modelo matem√°tico, n√£o existe uma ordem ou hierarquia nesses textos. O modelo n√£o sabe que 'cartao' √© diferente de 'nao_selecionado'. Se voc√™ tentasse converter essas palavras para n√∫meros diretamente (tipo 'cartao' = 1, 'boleto' = 2), o modelo poderia entender que 'boleto' √© "maior" que 'cartao', o que seria um erro.
> Cada linha recebe um `1` na coluna que corresponde √† sua categoria e um `0` nas outras. Isso garante que o modelo interprete cada categoria como uma caracter√≠stica independente, sem assumir nenhuma rela√ß√£o de ordem.

## Separar Features (X) e Alvo (y)

-> X: Todas as colunas de caracter√≠sticas (features).
-> y: A coluna que quero que o modelo aprenda a prever.

## Come√ßar com random forest
O **Random Forest** √© um algoritmo de aprendizado de m√°quina muito poderoso e geralmente √© uma excelente escolha para come√ßar. Ele funciona como uma "floresta de √°rvores de decis√£o". Em vez de usar apenas uma √°rvore para tomar a decis√£o, ele treina v√°rias √°rvores diferentes e combina o resultado delas para fazer uma previs√£o final. Isso o torna menos propenso a erros e geralmente mais preciso.

A sa√≠da, `RandomForestClassifier(n_jobs=-1, random_state=42)`, n√£o √© um resultado ou uma pontua√ß√£o. Ela √© apenas uma confirma√ß√£o de que o treinamento foi conclu√≠do com sucesso, e o objeto `rf_model` agora cont√©m um modelo "pronto para uso" com os par√¢metros que voc√™ definiu.

> [!NOTE]
> √© como um estudante que acabou de terminar de estudar para uma prova:
> - O comando `rf_model.fit(X_treino, y_treino)` √© o estudante lendo o livro did√°tico (`X_treino`) e o gabarito (`y_treino`).
> - A sa√≠da significa que o estudante terminou de estudar. Ele n√£o est√° mais vazio, ele "aprendeu" e est√° pronto para o teste.
> 

``` Markdown

Acur√°cia: 0.78
Relat√≥rio de Classifica√ß√£o:
precision    recall  f1-score   support
False       0.79      0.96      0.87      3227
True       0.68      0.26      0.38      1116


accuracy                            0.78      4343
macro avg       0.74      0.61      0.62      4343
weighted avg    0.76   0.78         0.74      4343


Matriz de Confus√£o:
[[3093  134]
[[826  290]]
```


3093 (Verdadeiros Negativos): O modelo disse que n√£o iria converter e o cliente realmente n√£o converteu. (Previs√£o correta!)
134 (Falsos Positivos): O modelo disse que iria converter, mas o cliente n√£o converteu. (Falso alarme)
826 (Falsos Negativos): O modelo disse que n√£o iria converter, mas o cliente realmente converteu. (falha! O modelo perdeu essas 826 oportunidades.)
290 (Verdadeiros Positivos): O modelo disse que iria converter e o cliente realmente converteu. (Previs√£o correta!)

### **O Relat√≥rio de Classifica√ß√£o: Entendendo os Resultados**

O relat√≥rio usa os n√∫meros da matriz para calcular m√©tricas mais f√°ceis de interpretar, dividindo-as por classe (`False` = n√£o converteu, `True` = converteu).

- **Acur√°cia (0.78):** De forma geral, o modelo acertou 78% das previs√µes. Parece bom, mas a acur√°cia pode enganar, pois a maioria dos seus clientes n√£o converte (`3227` vs `1116`), ent√£o o modelo acerta muito ao prever "n√£o converteu".
- **Precision (Precis√£o):**
    - `Precision` para a classe `True` (0.68): De todos os clientes que o modelo **previu** que iriam converter, apenas **68% realmente converteram**. Isso significa que, se voc√™ usasse o modelo para fazer uma campanha, 32% dos contatos seriam desperdi√ßados.
- **Recall (Sensibilidade):**
    - `Recall` para a classe `True` (0.26): De todos os clientes que **realmente converteram**, o modelo s√≥ conseguiu encontrar **26% deles**. Isso √© a m√©trica mais importante para o seu objetivo de "recupera√ß√£o de vendas". Um `Recall` baixo significa que o modelo est√° **deixando a maior parte das oportunidades passarem batido**.
### **Resumo da An√°lise**
O modelo **√© bom em identificar quem n√£o vai converter**, mas **n√£o √© muito bom em encontrar os clientes que realmente convertem**.
O `Recall` de 0.26 para a classe `True` (convers√£o) mostra que o modelo est√° perdendo a maioria das oportunidades. Isso √© normal para o primeiro modelo. Agora que voc√™ tem essa linha de base, o pr√≥ximo passo √© tentar melhor√°-la

- Definir uma grade de hiperpar√¢metros a serem testados.
- Usar o `GridSearchCV` para encontrar a combina√ß√£o que maximiza o `recall`, j√° que esta √© a m√©trica mais importante para o seu objetivo de recuperar clientes.
- Imprimir a melhor combina√ß√£o de par√¢metros e a pontua√ß√£o obtida.

Par√¢metros usados pra os ajustes:
- **`n_estimators`**: √â o n√∫mero de √°rvores de decis√£o que o modelo Random Forest ir√° construir. Pense em cada √°rvore como um "especialista" em prever a convers√£o. Quanto mais √°rvores, mais "opini√µes" o modelo considera para tomar a decis√£o final, o que geralmente aumenta a precis√£o. No seu caso, o valor ideal foi **150**.
    
- **`max_depth`**: √â a profundidade m√°xima que cada √°rvore pode ter. Controlar a profundidade √© crucial para evitar o **overfitting**, que √© quando o modelo aprende os dados de treino t√£o bem que n√£o consegue generalizar para dados novos. O `GridSearchCV` determinou que a profundidade ideal √© **10**.
    
> Ent√£o, o novo modelo ser√° um `RandomForestClassifier` com 150 √°rvores, e cada uma delas ter√° no m√°ximo 10 n√≠veis de profundidade. Isso garante que o modelo seja robusto, eficiente e tenha a melhor chance de prever com sucesso os clientes que podem ser recuperados!

O que o resultado da Matriz de Confus√£o nos diz √©:
- **`[[2263, 0], [737, 0]]`**
- **2263 Verdadeiros Negativos**: O modelo acertou todos os clientes que n√£o converteram.
- **0 Falsos Positivos**: O modelo n√£o previu nenhum cliente que converteria e que na verdade n√£o converteu.
- **737 Falsos Negativos**: O modelo previu que todos esses clientes n√£o iriam converter, mas eles **realmente converteram**. Este √© o n√∫mero total de clientes que converteram no seu conjunto de teste, e o modelo errou todos.
- **0 Verdadeiros Positivos**: O modelo n√£o acertou nenhum cliente que converteu.

## Usando Regress√£o log√≠stica

```
Treinando o modelo de Regress√£o Log√≠stica...

--- Avalia√ß√£o do Modelo de Regress√£o Log√≠stica ---
Relat√≥rio de Classifica√ß√£o:
               precision    recall  f1-score   support

       False       0.75      0.49      0.59      2263
        True       0.24      0.50      0.33       737

    accuracy                           0.49      3000
   macro avg       0.50      0.50      0.46      3000
weighted avg       0.63      0.49      0.53      3000

Matriz de Confus√£o:
 [[1112 1151]
 [ 366  371]]
```
Acur√°cia mais baixa que o randomforest , mas:
- **Matriz de Confus√£o:**
    - **Verdadeiros Positivos (371):** O modelo previu que 371 clientes iriam converter e acertou! Isso √© uma enorme melhoria em rela√ß√£o ao modelo anterior, que acertou 0.
    - **Falsos Negativos (366):** O modelo errou ao dizer que 366 clientes n√£o iriam converter, quando na verdade, eles converteram. O n√∫mero ainda √© alto, mas √© bem menor que os 737 erros do Random Forest.
- **Recall para a classe 'True' (0.50):**
    - Este √© o ponto principal. O modelo de Regress√£o Log√≠stica conseguiu identificar **50% de todos os clientes que realmente converteram**. Isso √© um resultado muito mais √∫til para o seu objetivo de "recuperar vendas" do que o `recall` de 0% do modelo anterior.
**Precision para a classe 'True' (0.24):**
- O `precision` √© baixo, o que significa que o modelo gerou muitos falsos positivos. De todos os clientes que ele sugeriu para a campanha, apenas 24% realmente converteram. Isso indica que a sua equipe teria que lidar com muitos "alarmes falsos."

> O de Regress√£o Log√≠stica tem um desempenho geral ruim, mas √© **muito mais √∫til** para o objetivo de encontrar clientes perdidos. Ele √© capaz de encontrar as oportunidades de venda (alto `recall`), mas com um custo de muitos "alarmes falsos" (baixo `precision`).


## **Relat√≥rio de Desempenho dos Modelos**

 **Random Forest (Inicial):** 
 - `Recall` para `converteu`: **0%**
 **Conclus√£o:** Modelo **n√£o serve** para o objetivo de recupera√ß√£o de vendas.

- **Random Forest (Otimizado):**
	- `Recall` para `converteu`: **0%**
    - **Conclus√£o:** Otimiza√ß√£o n√£o resolveu o problema de base.
        
- **Regress√£o Log√≠stica (com peso de classe):**
    - `Recall` para `converteu`: **50%**
    - **Conclus√£o:** Modelo **capaz de identificar metade** dos clientes que converteram.
        
> A Regress√£o Log√≠stica, mesmo com uma acur√°cia geral mais baixa, √© o **modelo vencedor** para o projeto, pois ele entrega a capacidade de identificar leads de alto valor que seriam perdidos de outra forma.

### **Taxa Estimada de Recupera√ß√£o de Vendas**
Com um `recall` de 50%, a **taxa estimada de recupera√ß√£o de vendas** do seu modelo √© de **50%**. Isso significa que, se voc√™ usar este modelo para identificar e abordar clientes que abandonaram o carrinho, pode recuperar at√© 50% dessas vendas perdidas.

### **Criando Amostras Preditivas**
O passo final √© criar a lista de clientes que voc√™ vai entregar para a equipe de vendas. Podemos filtrar o seu conjunto de teste para mostrar apenas os clientes que o modelo previu que iriam converter.

----
### **An√°lise Preditiva para Recupera√ß√£o de Vendas: Relat√≥rio de Conclus√£o**

#### **1. Introdu√ß√£o e Objetivo**

Este projeto teve como objetivo principal desenvolver um modelo de an√°lise preditiva para identificar clientes que, ap√≥s abandonarem o carrinho de compras, possuem alta probabilidade de converter em uma venda. O foco da an√°lise foi maximizar a **taxa de recupera√ß√£o de vendas** por meio da identifica√ß√£o de leads qualificados.

#### **2. Metodologia**

O processo seguiu uma metodologia padr√£o de ci√™ncia de dados, garantindo a robustez e a confiabilidade dos resultados:

- **Prepara√ß√£o dos Dados:** Foram selecionadas features relevantes para a predi√ß√£o, como `preco`, `metodo_pagamento`, `hora` e `tipo_plano`. Colunas que poderiam causar vazamento de dados, como `status_compra` e `taxa_conversao`, foram removidas. Vari√°veis categ√≥ricas foram transformadas em formato num√©rico usando a t√©cnica **One-Hot Encoding**.
- **Divis√£o e Treinamento:** O conjunto de dados foi dividido em 70% para treinamento e 30% para teste, garantindo que o desempenho do modelo fosse avaliado em dados n√£o utilizados durante o aprendizado.
- **Modelagem Preditiva:** Foram testados dois algoritmos de aprendizado de m√°quina: **Random Forest** e **Regress√£o Log√≠stica**.
- **Avalia√ß√£o:** A performance dos modelos foi avaliada com foco na m√©trica **Recall**, que mede a capacidade do modelo de identificar corretamente as oportunidades de venda.

#### **3. An√°lise e Resultados dos Modelos**

|Modelo Testado|Acur√°cia Geral|Recall (para Convers√£o)|Vantagem|Desvantagem|
|---|---|---|---|---|
|**Random Forest**|78%|**0%**|Alta acur√°cia geral.|**N√£o identificou nenhuma oportunidade de venda.**|
|**Regress√£o Log√≠stica**|49%|**50%**|**Identificou metade das oportunidades de venda.**|Acur√°cia geral mais baixa.|

Apesar de o modelo de **Random Forest** ter apresentado uma **acur√°cia** superior (78%), sua performance para o objetivo do projeto foi nula, com um **Recall de 0%**. Isso significa que o modelo n√£o conseguiu identificar corretamente nenhum cliente que, de fato, converteu, tornando-o ineficaz para a recupera√ß√£o de vendas.

O modelo de **Regress√£o Log√≠stica**, por outro lado, demonstrou ser o mais adequado. Embora sua acur√°cia geral seja de 49%, ele conseguiu um **Recall de 50%**, o que indica que √© capaz de encontrar metade de todos os clientes que converteram em vendas, mesmo que o modelo tenha gerado alguns "alarmes falsos" (Falsos Positivos).

#### **4. Conclus√£o e Recomenda√ß√£o Final**

Para o objetivo de **recupera√ß√£o de vendas**, o modelo de **Regress√£o Log√≠stica** √© a escolha ideal. Sua capacidade de identificar 50% das oportunidades perdidas representa um retorno tang√≠vel e direto para o neg√≥cio.
- **Taxa Estimada de Recupera√ß√£o de Vendas:** A taxa estimada de recupera√ß√£o √© de **50%** das vendas perdidas. 
- **Amostra Preditiva:** O modelo gerou uma amostra com 1.829 clientes que, com base nos dados, apresentam alta probabilidade de convers√£o.

A recomenda√ß√£o √© que essa amostra preditiva seja usada para direcionar os esfor√ßos de uma equipe de vendas ou de marketing, que pode focar seus recursos em clientes com maior probabilidade de retorno, otimizando o processo de recupera√ß√£o de vendas.
